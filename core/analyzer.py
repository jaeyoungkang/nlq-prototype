# core/analyzer.py
"""
í†µí•© ë¶„ì„ ì—”ì§„ - BigQuery ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° AI ë¶„ì„
"""

import os
import json
import time
import datetime
import logging
from typing import List, Dict, Optional, Generator

import anthropic
from google.cloud import bigquery
from google.cloud.exceptions import NotFound, BadRequest

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from utils.bigquery_utils import validate_table_ids
from utils.data_utils import (
    safe_json_serialize, 
    suggest_chart_config, 
    analyze_data_structure,
    generate_summary_insights
)

# config íŒ¨í‚¤ì§€ì—ì„œ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from config.prompts import (
    get_sql_generation_system_prompt,
    get_analysis_report_prompt,
    get_html_generation_prompt,
    get_profiling_system_prompt,
    get_specific_contextual_analysis_prompt
)

# ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ì ì„í¬íŠ¸
from config.schema_config import register_extracted_metadata

logger = logging.getLogger(__name__)


class BigQueryMetadataExtractor:
    """BigQuery ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸°"""
    
    def __init__(self, bigquery_client: bigquery.Client):
        self.client = bigquery_client
    
    def extract_metadata(self, project_id: str, table_ids: List[str]) -> Dict:
        """í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            "project_id": project_id,
            "tables": {},
            "summary": {
                "total_tables": len(table_ids),
                "total_rows": 0,
                "total_size_bytes": 0
            },
            "extracted_at": datetime.datetime.now().isoformat()
        }
        
        for table_id in table_ids:
            try:
                table = self.client.get_table(table_id)
                table_info = {
                    "table_id": table_id,
                    "num_rows": table.num_rows,
                    "num_bytes": table.num_bytes,
                    "created": table.created.isoformat() if table.created else None,
                    "modified": table.modified.isoformat() if table.modified else None,
                    "description": table.description or "",
                    "schema": [
                        {
                            "name": field.name,
                            "type": field.field_type,
                            "mode": field.mode,
                            "description": field.description or ""
                        }
                        for field in table.schema
                    ]
                }
                
                # íŒŒí‹°ì…”ë‹ ì •ë³´ ì¶”ê°€
                if table.time_partitioning:
                    table_info["partitioning"] = {
                        "type": table.time_partitioning.type_,
                        "field": table.time_partitioning.field
                    }
                
                # í´ëŸ¬ìŠ¤í„°ë§ ì •ë³´ ì¶”ê°€
                if table.clustering_fields:
                    table_info["clustering"] = {
                        "fields": list(table.clustering_fields)
                    }
                
                metadata["tables"][table_id] = table_info
                metadata["summary"]["total_rows"] += table.num_rows or 0
                metadata["summary"]["total_size_bytes"] += table.num_bytes or 0
                
            except NotFound:
                metadata["tables"][table_id] = {"error": "í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            except Exception as e:
                metadata["tables"][table_id] = {"error": str(e)}
        
        return metadata


class IntegratedAnalyzer:
    """í†µí•© ë¶„ì„ ì—”ì§„"""
    
    def __init__(self, anthropic_client: anthropic.Anthropic, bigquery_client: bigquery.Client):
        self.anthropic_client = anthropic_client
        self.bigquery_client = bigquery_client
        self.metadata_extractor = BigQueryMetadataExtractor(bigquery_client)
    
    def natural_language_to_sql(self, question: str, project_id: str, table_ids: List[str]) -> str:
        """ìì—°ì–´ ì§ˆë¬¸ì„ BigQuery SQLë¡œ ë³€í™˜"""
        if not self.anthropic_client:
            raise Exception("Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë™ì  ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = get_sql_generation_system_prompt(project_id, table_ids)
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1500,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": question}
                ]
            )
            
            sql_query = response.content[0].text.strip()
            
            # SQL ì¿¼ë¦¬ì—ì„œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            sql_query = self._clean_sql_query(sql_query)
            
            logger.info(f"ìƒì„±ëœ SQL: {sql_query}")
            return sql_query
            
        except Exception as e:
            raise Exception(f"Claude API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def _clean_sql_query(self, sql_query: str) -> str:
        """SQL ì¿¼ë¦¬ì—ì„œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì œê±° ë° ì •ë¦¬"""
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if '```sql' in sql_query:
            # ```sqlê³¼ ```ë¥¼ ì œê±°
            sql_query = sql_query.split('```sql')[1] if '```sql' in sql_query else sql_query
            sql_query = sql_query.split('```')[0] if '```' in sql_query else sql_query
        elif '```' in sql_query:
            # ì¼ë°˜ ì½”ë“œ ë¸”ë¡ ì œê±°
            parts = sql_query.split('```')
            if len(parts) >= 3:
                sql_query = parts[1]  # ì½”ë“œ ë¸”ë¡ ë‚´ìš©ë§Œ ì¶”ì¶œ
        
        # ì•ë’¤ ê³µë°± ì œê±°
        sql_query = sql_query.strip()
        
        # ì£¼ì„ì´ë‚˜ ì„¤ëª… ì œê±° (-- ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ë“¤ ì¤‘ SQL í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²ƒë“¤)
        lines = sql_query.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # SQL ì£¼ì„ì´ì§€ë§Œ ì‹¤ì œ SQL êµ¬ë¬¸ì´ í¬í•¨ëœ ê²½ìš°ëŠ” ìœ ì§€
            if line.startswith('--') and not any(keyword in line.upper() for keyword in ['SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER', 'LIMIT']):
                continue
            cleaned_lines.append(line)
        
        # ì •ë¦¬ëœ ë¼ì¸ë“¤ì„ ë‹¤ì‹œ ì¡°í•©
        sql_query = '\n'.join(cleaned_lines)
        
        # ì„¸ë¯¸ì½œë¡ ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        if not sql_query.rstrip().endswith(';'):
            sql_query = sql_query.rstrip() + ';'
        
        return sql_query
    
    def execute_bigquery(self, sql_query: str) -> Dict:
        """BigQueryì—ì„œ SQL ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            logger.info(f"ì‹¤í–‰í•  SQL: {sql_query}")
            
            query_job = self.bigquery_client.query(sql_query)
            results = query_job.result()
            
            rows = []
            for row in results:
                row_dict = {}
                try:
                    if hasattr(row, 'keys') and hasattr(row, 'values'):
                        for key, value in zip(row.keys(), row.values()):
                            if isinstance(value, datetime.datetime):
                                row_dict[key] = value.isoformat()
                            elif hasattr(value, 'isoformat'):
                                row_dict[key] = value.isoformat()
                            else:
                                row_dict[key] = value
                    else:
                        row_dict = dict(row)
                        for key, value in row_dict.items():
                            if isinstance(value, datetime.datetime):
                                row_dict[key] = value.isoformat()
                            elif hasattr(value, 'isoformat'):
                                row_dict[key] = value.isoformat()
                except Exception as e:
                    logger.error(f"Row ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                    row_dict = {"error": f"Row ë³€í™˜ ì‹¤íŒ¨: {str(e)}"}
                
                rows.append(row_dict)
            
            # ì•ˆì „í•œ job_stats ìƒì„± (ì†ì„±ì´ ì—†ì„ ê²½ìš° None ì²˜ë¦¬)
            job_stats = {}
            try:
                job_stats["bytes_processed"] = getattr(query_job, 'total_bytes_processed', None)
                job_stats["bytes_billed"] = getattr(query_job, 'total_bytes_billed', None)
                
                # creation_time ì†ì„± ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                creation_time = getattr(query_job, 'creation_time', None) or getattr(query_job, 'created', None)
                if creation_time and hasattr(creation_time, 'isoformat'):
                    job_stats["creation_time"] = creation_time.isoformat()
                else:
                    job_stats["creation_time"] = None
                
                # end_time ì†ì„± ì•ˆì „í•˜ê²Œ ì²˜ë¦¬  
                end_time = getattr(query_job, 'end_time', None) or getattr(query_job, 'ended', None)
                if end_time and hasattr(end_time, 'isoformat'):
                    job_stats["end_time"] = end_time.isoformat()
                else:
                    job_stats["end_time"] = None
                    
                # job_id ì¶”ê°€
                job_stats["job_id"] = getattr(query_job, 'job_id', None)
                
            except Exception as e:
                logger.warning(f"Job stats ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                job_stats = {
                    "bytes_processed": None,
                    "bytes_billed": None,
                    "creation_time": None,
                    "end_time": None,
                    "job_id": None
                }
            
            return {
                "success": True,
                "data": rows,
                "row_count": len(rows),
                "job_stats": job_stats
            }
            
        except Exception as e:
            logger.error(f"BigQuery ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "data": [],
                "error_type": "execution_error"
            }
    
    def generate_analysis_report(self, question: str, sql_query: str, query_results: List[Dict]) -> Dict:
        """êµ¬ì¡°í™”ëœ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.anthropic_client:
            raise Exception("Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not query_results:
            return {
                "report": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "chart_config": None,
                "data_summary": None,
                "insights": []
            }
        
        # ë°ì´í„° êµ¬ì¡° ë¶„ì„
        data_analysis = analyze_data_structure(query_results)
        summary_insights = generate_summary_insights(data_analysis, question)
        
        # ì°¨íŠ¸ ì„¤ì • ì œì•ˆ
        columns = list(query_results[0].keys()) if query_results else []
        chart_config = suggest_chart_config(query_results, columns)
        
        # ë°ì´í„° ìš”ì•½ ìƒì„±
        data_summary = {
            "overview": {
                "total_rows": len(query_results),
                "columns_count": len(columns),
                "data_types": {col: stats["type"] for col, stats in data_analysis["columns"].items()},
                "data_quality_score": data_analysis.get("data_quality", {}).get("overall_score", 0)
            },
            "key_statistics": data_analysis["columns"],
            "quick_insights": summary_insights
        }
        
        # Claudeë¥¼ ì‚¬ìš©í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        analysis_prompt = get_analysis_report_prompt(
            question, sql_query, data_analysis, summary_insights, query_results
        )
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=3000,
                messages=[
                    {"role": "user", "content": analysis_prompt}
                ]
            )
            
            analysis_report = response.content[0].text.strip()
            
            return {
                "report": analysis_report,
                "chart_config": chart_config,
                "data_summary": data_summary,
                "insights": summary_insights,
                "data_analysis": data_analysis
            }
            
        except Exception as e:
            raise Exception(f"ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def generate_html_report(self, question: str, sql_query: str, query_results: List[Dict]) -> Dict:
        """ì°½ì˜ì  HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.anthropic_client:
            raise Exception("Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not query_results:
            return {
                "html_content": self._generate_fallback_html(question, []),
                "quality_score": 60,
                "attempts": 1,
                "fallback": True
            }
        
        # HTML ìƒì„± í”„ë¡¬í”„íŠ¸
        html_prompt = get_html_generation_prompt(question, sql_query, query_results)
        
        max_attempts = 2
        for attempt in range(max_attempts):
            try:
                response = self.anthropic_client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=4000,
                    messages=[
                        {"role": "user", "content": html_prompt}
                    ]
                )
                
                html_content = response.content[0].text.strip()
                
                # HTML ì •ë¦¬
                if not html_content.startswith('<!DOCTYPE') and not html_content.startswith('<html'):
                    if '```html' in html_content:
                        html_content = html_content.split('```html')[1].split('```')[0].strip()
                    elif '```' in html_content:
                        html_content = html_content.split('```')[1].strip()
                
                # ê¸°ë³¸ í’ˆì§ˆ ê²€ì¦
                quality_score = self._validate_html_quality(html_content)
                
                if quality_score >= 70:
                    return {
                        "html_content": html_content,
                        "quality_score": quality_score,
                        "attempts": attempt + 1,
                        "fallback": False
                    }
                
                if attempt < max_attempts - 1:
                    logger.info(f"HTML í’ˆì§ˆ ê°œì„  í•„ìš” (ì ìˆ˜: {quality_score}), ì¬ì‹œë„ ì¤‘...")
                
            except Exception as e:
                logger.error(f"HTML ìƒì„± ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ í´ë°±
        return {
            "html_content": self._generate_fallback_html(question, query_results),
            "quality_score": 60,
            "attempts": max_attempts,
            "fallback": True
        }
    
    def _validate_html_quality(self, html_content: str) -> int:
        """HTML í’ˆì§ˆ ê°„ë‹¨ ê²€ì¦"""
        score = 100
        
        if not html_content.startswith('<!DOCTYPE'):
            score -= 20
        if 'Chart.js' in html_content and 'cdnjs.cloudflare.com' not in html_content:
            score -= 20
        if 'new Chart(' not in html_content:
            score -= 15
        if '<style>' not in html_content:
            score -= 15
        
        return max(0, score)
    
    def _generate_fallback_html(self, question: str, query_results: List[Dict]) -> str:
        """í´ë°± HTML ìƒì„±"""
        return f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{question} - ë¶„ì„ ê²°ê³¼</title>
    <style>
        body {{ font-family: 'Segoe UI', sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }}
        .container {{ max-width: 800px; margin: 0 auto; background: white; border-radius: 12px; padding: 30px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; margin-bottom: 30px; color: #333; }}
        .data-table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        .data-table th {{ background: #4285f4; color: white; padding: 12px; text-align: left; }}
        .data-table td {{ padding: 10px; border-bottom: 1px solid #ddd; }}
        .summary {{ background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š {question}</h1>
            <p>BigQuery ë¶„ì„ ê²°ê³¼ â€¢ {len(query_results)}ê°œ ê²°ê³¼</p>
        </div>
        <div class="summary">
            <h3>ğŸ“‹ ê¸°ë³¸ ë¶„ì„ ë¦¬í¬íŠ¸</h3>
            <p>ì´ {len(query_results)}ê°œì˜ ë ˆì½”ë“œê°€ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.</p>
        </div>
    </div>
</body>
</html>"""

    def generate_specific_analysis(self, question: str, sql_query: str, query_results: List[Dict], 
                                 project_id: str, table_ids: List[str], analysis_type: str) -> str:
        """íŠ¹ì • íƒ€ì…ì˜ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ìƒì„±"""
        if not self.anthropic_client:
            raise Exception("Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if not query_results:
            return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ì–´ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤."

        # get_specific_contextual_analysis_prompt í•¨ìˆ˜ë¥¼ ì‚¬ìš©
        analysis_prompt = get_specific_contextual_analysis_prompt(
            question, sql_query, query_results, project_id, table_ids, analysis_type
        )

        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2000,
                messages=[
                    {"role": "user", "content": analysis_prompt}
                ]
            )
            specific_analysis = response.content[0].text.strip()
            return specific_analysis
        except Exception as e:
            logger.error(f"íŠ¹ì • ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return f"ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def generate_contextual_analysis(self, question: str, sql_query: str, query_results: List[Dict], 
                                   project_id: str, table_ids: List[str]) -> str:
        """ì¿¼ë¦¬ ê²°ê³¼ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ìƒì„±"""
        # ìƒˆë¡œìš´ generate_specific_analysis ë©”ì„œë“œë¥¼ ì‚¬ìš©
        return self.generate_specific_analysis(
            question, sql_query, query_results, project_id, table_ids, 'context'
        )